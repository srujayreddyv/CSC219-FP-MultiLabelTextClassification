Toxic Comment Classification Dataset
------------------------------------

Overview:
The Toxic Comment Classification dataset is a collection of comments from Wikipedia's talk page edits, labeled for various types of toxic behavior. This dataset was used in the "Toxic Comment Classification Challenge" hosted by Jigsaw/Conversation AI.

Contents:
The dataset includes multiple labels for each comment, categorizing them into different types of toxicity. The labels are:
- Toxic
- Severe Toxic
- Obscene
- Threat
- Insult
- Identity Hate

Purpose:
The dataset is intended for the development and evaluation of machine learning models, particularly for multi-label text classification tasks. It is designed to aid in the automatic detection of toxic behavior in online discussions, contributing to healthier and more productive online interactions.

@misc{jigsaw-toxic-comment-classification-challenge,
    author = {cjadams, Jeffrey Sorensen, Julia Elliott, Lucas Dixon, Mark McDonald, nithum, Will Cukierski},
    title = {Toxic Comment Classification Challenge},
    publisher = {Kaggle},
    year = {2017},
    url = {https://kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge}
}
